# Redis Cache Configuration and Structure
# Real-time data caching, session management, and performance optimization

# Session Management
# Key pattern: session:{session_id}
# TTL: 8 hours (28800 seconds)
# Data structure: Hash
# Fields:
# - user_id: string
# - company_id: string
# - user_agent: string
# - ip_address: string
# - created_at: timestamp
# - last_activity: timestamp
# - permissions: JSON string (serialized permissions)
# - metadata: JSON string (additional session data)

# User Rate Limiting
# Key pattern: rate_limit:user:{user_id}:{endpoint}
# TTL: 1 hour (3600 seconds)
# Data structure: String (counter)
# Purpose: API rate limiting per user per endpoint

# Company Rate Limiting
# Key pattern: rate_limit:company:{company_id}
# TTL: 1 hour (3600 seconds)
# Data structure: Hash
# Fields:
# - api_calls: integer
# - ai_requests: integer
# - document_uploads: integer
# - export_requests: integer

# Active Users Cache
# Key pattern: active_users:{company_id}
# TTL: 5 minutes (300 seconds)
# Data structure: Set
# Purpose: Track active users for real-time features

# AI Analysis Cache
# Key pattern: ai_cache:{document_hash}
# TTL: 7 days (604800 seconds)
# Data structure: Hash
# Fields:
# - analysis_result: JSON string
# - confidence_score: float
# - model_version: string
# - created_at: timestamp
# - cache_hits: integer

# Tender Analytics Cache
# Key pattern: tender_analytics:{company_id}:{date}
# TTL: 24 hours (86400 seconds)
# Data structure: Hash
# Fields:
# - total_tenders: integer
# - active_tenders: integer
# - completed_tenders: integer
# - average_response_time: float
# - top_suppliers: JSON string

# Real-time Notifications Queue
# Key pattern: notifications:queue:{user_id}
# TTL: 30 days (2592000 seconds)
# Data structure: List (FIFO queue)
# Purpose: Queue notifications for real-time delivery

# Document Processing Status
# Key pattern: doc_processing:{job_id}
# TTL: 24 hours (86400 seconds)
# Data structure: Hash
# Fields:
# - status: string (queued|processing|completed|failed)
# - progress: integer (0-100)
# - started_at: timestamp
# - completed_at: timestamp
# - result: JSON string (when completed)
# - error: string (when failed)

# Search Results Cache
# Key pattern: search:{query_hash}:{filters_hash}
# TTL: 1 hour (3600 seconds)
# Data structure: String (JSON serialized results)
# Purpose: Cache frequently searched queries

# Dashboard Data Cache
# Key pattern: dashboard:{user_id}:{widget_type}
# TTL: 15 minutes (900 seconds)
# Data structure: String (JSON serialized widget data)
# Purpose: Cache dashboard widget data for performance

# System Health Metrics
# Key pattern: metrics:{metric_type}:{timestamp}
# TTL: 30 days (2592000 seconds)
# Data structure: Hash
# Purpose: Store system performance metrics

# WebSocket Connection Tracking
# Key pattern: websocket:{user_id}
# TTL: 24 hours (86400 seconds)
# Data structure: Set
# Purpose: Track active WebSocket connections per user

# Supplier Evaluation Cache
# Key pattern: supplier_eval:{supplier_id}:{criteria_hash}
# TTL: 12 hours (43200 seconds)
# Data structure: Hash
# Fields:
# - evaluation_score: float
# - criteria_scores: JSON string
# - last_updated: timestamp
# - evaluator_id: string

# Calendar Events Cache
# Key pattern: calendar:{company_id}:{month_year}
# TTL: 6 hours (21600 seconds)
# Data structure: String (JSON serialized events)
# Purpose: Cache monthly calendar data

# Configuration Examples:

# Redis Configuration Commands
# These should be run when setting up Redis for the application

# Set default memory policy
CONFIG SET maxmemory-policy allkeys-lru

# Enable keyspace notifications for expired keys
CONFIG SET notify-keyspace-events Ex

# Set reasonable timeout for client connections
CONFIG SET timeout 300

# Configure slow log for monitoring
CONFIG SET slowlog-log-slower-than 10000
CONFIG SET slowlog-max-len 128

# Redis Lua Scripts for Complex Operations

# Atomic session creation with rate limiting check
local session_creation_script = [[
    local session_key = KEYS[1]
    local rate_limit_key = KEYS[2]
    local session_data = ARGV[1]
    local session_ttl = ARGV[2]
    local rate_limit = ARGV[3]
    local rate_limit_ttl = ARGV[4]
    
    local current_rate = redis.call('GET', rate_limit_key)
    if current_rate and tonumber(current_rate) >= tonumber(rate_limit) then
        return nil  -- Rate limit exceeded
    end
    
    redis.call('HMSET', session_key, unpack(cjson.decode(session_data)))
    redis.call('EXPIRE', session_key, session_ttl)
    redis.call('INCR', rate_limit_key)
    redis.call('EXPIRE', rate_limit_key, rate_limit_ttl)
    
    return 'OK'
]]

# Cache invalidation pattern script
local cache_invalidation_script = [[
    local pattern = KEYS[1]
    local cursor = '0'
    local keys_deleted = 0
    
    repeat
        local result = redis.call('SCAN', cursor, 'MATCH', pattern, 'COUNT', 100)
        cursor = result[1]
        local keys = result[2]
        
        if #keys > 0 then
            keys_deleted = keys_deleted + redis.call('DEL', unpack(keys))
        end
    until cursor == '0'
    
    return keys_deleted
]]

# Performance monitoring script
local performance_monitoring_script = [[
    local metric_key = KEYS[1]
    local timestamp = ARGV[1]
    local metrics = cjson.decode(ARGV[2])
    
    for key, value in pairs(metrics) do
        redis.call('HSET', metric_key, key, value)
        redis.call('HSET', metric_key, 'timestamp', timestamp)
    end
    
    redis.call('EXPIRE', metric_key, 2592000)  -- 30 days TTL
    return 'OK'
]]
